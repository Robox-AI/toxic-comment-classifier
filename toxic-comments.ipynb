{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge\n",
    "\n",
    "<font color=red>**Warning:**</font>\n",
    "The content of many of these comments are incredibly inappropriate and will be offensive. In the [View results](#view-results) section we'll be exploring some of the accuracies of the model predictions which will expose some of these terrible comments.\n",
    "\n",
    "See https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules before executing user code\n",
    "%reload_ext autoreload\n",
    "# Reload all modules (except those excluded by %aimport)\n",
    "%autoreload 2\n",
    "# Show plots within this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and test data into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='download/'\n",
    "test_csv = f'{PATH}test.csv'\n",
    "train_csv = f'{PATH}train.csv'\n",
    "sample_submission_csv = f'{PATH}sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(train_csv, na_filter=False)\n",
    "test_df = pd.read_csv(test_csv, na_filter=False)\n",
    "submission_df = pd.read_csv(sample_submission_csv, nrows=0) # copy column headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "Examine the labels and how the data is organized within this framework. Let's first add a \"none\" column to represent comments with no labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train_df['none'] = 1-train_df[label_cols].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>003217c3eb469ba9</td>\n",
       "      <td>Hi! I am back again!\\nLast warning!\\nStop undo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "79  003217c3eb469ba9  Hi! I am back again!\\nLast warning!\\nStop undo...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  none  \n",
       "79      1             0        0       1       0              0     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['threat'] == 1].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the labels are all in the same scale and won't need to be standardized. Notice how a comment can have multiple labels (e.g., the comment above is both toxic and a threat). Let's now take a quick look at the shape of our dataset to get an idea of scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 159571 rows, which is essentially the number of comments in our dataset. There are 8 columns, 6 of which correspond to the individual labels we will be using for comment characterization. But how many comments actually fall into each of these categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate           none  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting statistics here. First, it's clear that zeros dominate our dataset. That can be seen a number of ways, like how each quartile from 25-75 percent are 0, and how the mean in each column is close to zero. Because they are zeros and ones, the mean can be easily converted into a percentage (of ones) by multiplying by 100 (i.e., 9.58% of comments are toxic, 1.0% of comments are severely toxic, 5.3% are obscene, etc.). Lastly, let's do a quick check to make sure none of the values in our dataset are null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 9 columns):\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "none             159571 non-null int64\n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info() # verify that are no missing values in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have no null values (like NaNs) in our dataset, so it's already very clean. Now that we have a good grip on what we are working with, it'll be good for us to figure out how we wish to actually analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for analysis\n",
    "\n",
    "This looks like a multilabel text classification problem, which can be solved in a variety of ways.\n",
    "\n",
    "**(1) Problem transformation methods**\n",
    "\n",
    "Problem transformation transforms the multilabel input into a representation suitable for single-label classification methods.\n",
    "\n",
    "* **Binary Relevance** - Independently train one binary classifier for each label. The drawback of this method is that it does not take into account label correlation.\n",
    "\n",
    "* **Label Powerset** - Generate a new class for every combination of labels and then use multiclass classification. Unlike binary relevance, this method takes into account label correlation, but it leads to a large number of classes and fewer examples per class. \n",
    "\n",
    "* **Classifier Chains** - Based on Binary Relevance but predictions of binary classifiers are cascaded along a chain as additional features. This method takes into account label correlation but the order of classifiers in the chain changes results.\n",
    "\n",
    "**(2) Algorithm adaptation methods**\n",
    "\n",
    "Algorithm adaption extends existing single-label classifier algorithms to handle multilabel data directly.\n",
    "\n",
    "- - - - - -\n",
    "\n",
    "We are going to use the Binary Relevance method in order to classify comments into the different categories. We encourage readers to look into the other methods as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate target features (y) from input features (X) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use sklearn.model_selection.train_test_split to split training data into validation and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = train_df['comment_text']\n",
    "y = train_df[['obscene','insult','toxic','severe_toxic','identity_hate','threat']]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_test = test_df['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count how many times each word appears in the comments (term frequency) and multiply it by the context-adjusted weight of each word (inverse document frequency). Better explained here: https://www.quora.com/How-does-TfidfVectorizer-work-in-laymans-terms\n",
    "\n",
    "Here we are transforming our input data into a TF-IDF matrix, aka a document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TODO: Research TfidfVectorizer and figure out what would be useful parameters to pass\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_docterm = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# transform validation and test data to have the same shape\n",
    "# TODO: Ultimately we are going to want to use cross-validation so we don't lose out on training data\n",
    "X_valid_docterm = vectorizer.transform(X_valid)\n",
    "X_test_docterm = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "dt_matrix = pd.DataFrame(X_train_docterm.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 165609)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allowed</th>\n",
       "      <th>attack</th>\n",
       "      <th>be</th>\n",
       "      <th>blocked</th>\n",
       "      <th>but</th>\n",
       "      <th>comments</th>\n",
       "      <th>definitely</th>\n",
       "      <th>editor</th>\n",
       "      <th>editors</th>\n",
       "      <th>if</th>\n",
       "      <th>...</th>\n",
       "      <th>that</th>\n",
       "      <th>the</th>\n",
       "      <th>their</th>\n",
       "      <th>they</th>\n",
       "      <th>this</th>\n",
       "      <th>to</th>\n",
       "      <th>ve</th>\n",
       "      <th>while</th>\n",
       "      <th>will</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200271</td>\n",
       "      <td>0.184008</td>\n",
       "      <td>0.154242</td>\n",
       "      <td>0.299486</td>\n",
       "      <td>0.088722</td>\n",
       "      <td>0.159946</td>\n",
       "      <td>0.21692</td>\n",
       "      <td>0.165467</td>\n",
       "      <td>0.156545</td>\n",
       "      <td>0.171023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066082</td>\n",
       "      <td>0.049339</td>\n",
       "      <td>0.266064</td>\n",
       "      <td>0.223291</td>\n",
       "      <td>0.07312</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.133756</td>\n",
       "      <td>0.15515</td>\n",
       "      <td>0.105123</td>\n",
       "      <td>0.18268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    allowed    attack        be   blocked       but  comments  definitely  \\\n",
       "0  0.200271  0.184008  0.154242  0.299486  0.088722  0.159946     0.21692   \n",
       "\n",
       "     editor   editors        if   ...         that       the     their  \\\n",
       "0  0.165467  0.156545  0.171023   ...     0.066082  0.049339  0.266064   \n",
       "\n",
       "       they     this        to        ve    while      will      won  \n",
       "0  0.223291  0.07312  0.161087  0.133756  0.15515  0.105123  0.18268  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_matrix.head(1).loc[:, (dt_matrix.head(1) != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train one binary classifier for each label. This is called binary relevance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression(C=4, dual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy for obscene comments is 0.9786620711264296\n",
      "Validation accuracy for insult comments is 0.9722387592041359\n",
      "Validation accuracy for toxic comments is 0.9609901300328999\n",
      "Validation accuracy for severe_toxic comments is 0.9904120319598935\n",
      "Validation accuracy for identity_hate comments is 0.9924800250665831\n",
      "Validation accuracy for threat comments is 0.9972426758577472\n"
     ]
    }
   ],
   "source": [
    "# Train and check the prediction accuracy on the validation dataset\n",
    "for label in y_train:\n",
    "    y_train_col = y_train[label]\n",
    "    logreg.fit(X_train_docterm, y_train_col)\n",
    "    y_valid_col = y_valid[label]\n",
    "    y_pred = logreg.predict(X_valid_docterm)\n",
    "    print(\"Validation accuracy for {} comments is {}\".format(label, accuracy_score(y_valid_col, y_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for obscene comments is [0.08198686 0.00013583 0.00096841 ... 0.00041707 0.00052045 0.00222638]\n",
      "Prediction for insult comments is [0.08198686 0.00013583 0.00096841 ... 0.00041707 0.00052045 0.00222638]\n",
      "Prediction for toxic comments is [0.08198686 0.00013583 0.00096841 ... 0.00041707 0.00052045 0.00222638]\n",
      "Prediction for severe_toxic comments is [0.08198686 0.00013583 0.00096841 ... 0.00041707 0.00052045 0.00222638]\n",
      "Prediction for identity_hate comments is [0.08198686 0.00013583 0.00096841 ... 0.00041707 0.00052045 0.00222638]\n",
      "Prediction for threat comments is [0.08198686 0.00013583 0.00096841 ... 0.00041707 0.00052045 0.00222638]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "for label in y_train:\n",
    "    # predict_proba returns two probabilities: the probability that it has the label or does not\n",
    "    y_prob_test = logreg.predict_proba(X_test_docterm)[:, 1] # we only want the probability that it has this label\n",
    "    submission_df[label] = y_prob_test\n",
    "    print(\"Prediction for {} comments is {}\".format(label, y_prob_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results\n",
    "\n",
    "<font color=red>**Warning:**</font>\n",
    "The content of many of these comments are incredibly inappropriate and will be offensive. In this section we'll be exploring some of the accuracies of the model predictions which will expose some of these terrible comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.081987</td>\n",
       "      <td>0.081987</td>\n",
       "      <td>0.081987</td>\n",
       "      <td>0.081987</td>\n",
       "      <td>0.081987</td>\n",
       "      <td>0.081987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.081987      0.081987  0.081987  0.081987  0.081987   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.081987  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare submission\n",
    "submission_df['id'] = test_df['id'].tolist()\n",
    "submission_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at a comment with a high probability of being labeled toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                       comment_text\n",
      "277   00795a46cc1c7816  T IS PEOPLE LIKE YOU THAT MAKE WIKIPEDIA HORRI...\n",
      "4318  075a19ec9c94796e  WHY ARE YOU BLOCKED ME, YOU LITTHE... BECAUSE ...\n",
      "8067  0d8d8d475b4b676a                                DIE! DIE! DIE! DIE!\n"
     ]
    }
   ],
   "source": [
    "print(test_df.loc[submission_df['toxic'] > 0.9].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check that the probability these comments are labeled toxic is about 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       toxic\n",
      "277  0.99468\n"
     ]
    }
   ],
   "source": [
    "print(submission_df.loc[submission_df['id'] == '00795a46cc1c7816'][['toxic']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check proabilities for all the labels for this comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     severe_toxic  obscene   threat   insult\n",
      "277       0.99468  0.99468  0.99468  0.99468\n"
     ]
    }
   ],
   "source": [
    "print(submission_df.loc[submission_df['id'] == '00795a46cc1c7816'][['severe_toxic', 'obscene', 'threat', 'insult']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Figure out why these probabilities are all the same. That's a sign the there's something wrong with the nerual net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at a comment with a low probability of being labeled toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n"
     ]
    }
   ],
   "source": [
    "print(test_df.loc[submission_df['toxic'] < 0.05].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['== From RfC == \\n\\n The title is fine as it is, IMO.']\n"
     ]
    }
   ],
   "source": [
    "print(test_df.loc[submission_df['id'] == '0000247867823ef7'].comment_text.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to CSV for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
